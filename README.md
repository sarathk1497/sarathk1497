♦️ Intro

Hi Techies! 👋🌱 I'm a Data Engineer with over 7 years of professional experience.I specialize in Python, PySpark, SQL, AWS, GCP, Kafka, OOPS, and Data Engineering System Design.I currently serve as Senior Data Engineer at Hartford Financial Services Group.

🌱 My professional work includes developing:

▶️ Real-time Financial Transaction Data Pipeline & Anomaly DetectionBuilt a robust real-time pipeline using Apache Spark, Kafka, and AWS Glue to ingest and process financial transactions.Integrated fraud detection logic, reducing anomaly detection time from 24 hours to under 30 minutes.Delivered interactive Power BI dashboards while ensuring compliance with SOX and GDPR.

🌱 I am well-versed in:

Python, PySpark, SQL, OOPS, Data Engineering System Design

Data Modelling, ETL, Batch & Streaming Pipelines, Kafka, Airflow

Cloud Services:

GCP: GCS, BigQuery, Dataflow, Looker Studio

AWS: S3, Lambda, SNS, Glue, Redshift, RDS, Athena

🌱 I’ve built robust pipelines for both batch and stream processing using GCP, AWS, Snowflake, and more.

♦️ Skills 💻

Programming: Python, PySpark, SQL

Cloud:

AWS: S3, Lambda, Glue, Redshift, RDS, Athena

GCP: GCS, BigQuery, Dataflow

Tools: VSCode, Tableau, Airflow

Concepts: Data Modelling, ETL, Data Orchestration, System Design

♦️ Connect with Me 🔗

📧 Email:sarathk8901@gmail.com

🌐 Portfolio: https://sarathk1497.github.io/sarathchandrikak.github.io/

🔗 LinkedIn: https://www.linkedin.com/in/sarath-k14/
