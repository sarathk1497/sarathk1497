# 👋 Hi there, I'm Sarath Chandrika!

💻 **Data Engineer** | 🛠️ System Design | 🌩️ GCP & AWS | ⚡Batch and Real-Time Streaming

---

🔍 **About Me**

I'm a passionate and results-driven **Senior Data Engineer** with **6+ years of experience** designing and implementing large-scale, cloud-native data solutions across finance, retail, and tech sectors.  
I specialize in transforming raw data into powerful insights through **streaming pipelines**, **data lake architectures**, and **cloud platform engineering**.

---

🚀 **What I Do**

- Architect **real-time fraud detection pipelines** using **Kafka, Spark, Glue, and S3**
- Lead **data migration** projects from legacy systems (MySQL, Oracle, Teradata, SAS) to **modern cloud platforms** (BigQuery, Athena, Redshift)
- Optimize ETL performance with **Airflow, dbt, PySpark, and SQL**
- Build **event-driven, cost-efficient architectures** on **AWS & GCP**
- Develop insightful dashboards using **Power BI, Looker Studio**, and enable **self-service analytics**

---
## 🎯 Core Expertise

### 🚀 Programming & Design  
- 🐍 Python • ⚡ PySpark • 🧠 SQL • 🧱 OOP Principles • 🏗️ System Design 

### 💡 Data Engineering & Pipelines  
- 🗂️ Data Modeling • 🔄 ETL • ⏱️ Batch & 🔃 Real-Time Streaming  
- 📬 Apache Kafka • 🛠️ Workflow Orchestration using Airflow

### ☁️ Cloud Services  
**🟧 Amazon Web Services (AWS):** 🧊 S3 • 🌀 Lambda • 📣 SNS • 🧪 Glue • 🏢 Redshift 
**🌐 Google Cloud Platform (GCP):** 🪣 GCS • 📊 BigQuery • 🔁 Dataflow

### 🧰 Tools & IDEs  
- 🧑‍💻 Git • 💻 VS Code 


---

📂 **Featured Projects**

### 💳 Financial Transaction Data Pipeline & Anomaly Detection  
- Built a robust **real-time pipeline** using **Apache Spark**, **AWS Glue**, and **Kafka** to ingest and process financial transactions  
- Integrated custom anomaly detection logic to flag fraud, **reducing detection time from 24 hours to under 30 minutes**  
- Ensured compliance with **SOX** and **GDPR**, while delivering interactive dashboards in **Power BI**

### ☁️ Modern Data Lake Migration & Report Optimization  
- Migrated legacy **MySQL** and **Oracle** systems to an **AWS-based data lake** using **Glue**, **dbt**, and **Athena**  
- Automated **hourly ETL refreshes** with **Apache Airflow** and **Looker dashboards**  
- Achieved **50% reduction in report refresh times**, saving the business **$80K annually** through self-service analytics


---

📫 **Let's Connect**

- 📧 Email: [sarathk8901@gmail.com](mailto:sarathk8901@gmail.com)  
- 🔗 [LinkedIn](www.linkedin.com/in/sarath-k14)  
- 🌐 [Portfolio](https://sarathk1497.github.io/sarathchandrikak.github.io/)
- 

---

🧠 **Currently Learning**

- Real-time stream processing with **Spark Structured Streaming**  
- **Data quality automation** using **Great Expectations**  

---

💬 “Data is not just information – it’s your competitive advantage. I engineer that edge.”

---

